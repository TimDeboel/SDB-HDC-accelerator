{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import image\n",
    "import os\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import numpy as np\n",
    "import numpy.linalg as lin\n",
    "import scipy.special as ss\n",
    "from dataclasses import dataclass\n",
    "import copy\n",
    "\n",
    "# Convert binary text into a list\n",
    "def convert_to_list(raw_img):\n",
    "  converted_list = []\n",
    "  temp_row = []\n",
    "  for i in raw_img:\n",
    "    if(i != '\\n'):\n",
    "      if(i == '0'):\n",
    "        temp_row.append(0)\n",
    "      else:\n",
    "        temp_row.append(1)\n",
    "    else:\n",
    "      converted_list.append(temp_row)\n",
    "      temp_row = []\n",
    "\n",
    "  return converted_list\n",
    "\n",
    "###############################################\n",
    "# Displaying listed data as images\n",
    "###############################################\n",
    "def display_img(img_data):\n",
    "  plt.imshow(img_data, cmap='Greys',  interpolation='nearest')\n",
    "  plt.axis('off')\n",
    "  return\n",
    "\n",
    "###############################################\n",
    "# Adding noise to the system\n",
    "###############################################\n",
    "def add_noise(data,noise_prob):\n",
    "\n",
    "  # Initialize noisy data\n",
    "  noisy_data = []\n",
    "\n",
    "  # Sanity checker\n",
    "  if(noise_prob < 0 or noise_prob > 1):\n",
    "    print(\"Error! Noise probability isn't correct\")\n",
    "    return\n",
    "\n",
    "  # Get total length per row\n",
    "  col_length = len(data[0])\n",
    "\n",
    "  # Generate fixed length\n",
    "  shuffle_list = [x for x in range(col_length)]\n",
    "  cutoff_idx = round(col_length * noise_prob)\n",
    "\n",
    "  # Iterate per row\n",
    "  for row in data:\n",
    "\n",
    "    # Do random indexing\n",
    "    random.shuffle(shuffle_list)\n",
    "    temp_row = []\n",
    "\n",
    "    # Start flipping bits\n",
    "    for i in range(col_length):\n",
    "      if(shuffle_list[i] < cutoff_idx):\n",
    "        if(row[i] == 0):\n",
    "          temp_row.append(1)\n",
    "        else:\n",
    "          temp_row.append(0)\n",
    "      else:\n",
    "        temp_row.append(row[i])\n",
    "\n",
    "    noisy_data.append(temp_row)\n",
    "\n",
    "  return noisy_data\n",
    "\n",
    "###############################################\n",
    "# This just displays a clean set of letters\n",
    "###############################################\n",
    "def show_set(clean_letters):\n",
    "\n",
    "  fig, axs = plt.subplots(6, 5, figsize=(20, 20))\n",
    "\n",
    "  counter = 0\n",
    "  for i in range(5):\n",
    "    for j in range(5):\n",
    "      axs[i,j].imshow(1-np.reshape(clean_letters[i*5+j],(7,5)), cmap='Greys',  interpolation='nearest')\n",
    "\n",
    "  axs[5,0].axis('off')\n",
    "  axs[5,1].axis('off')\n",
    "\n",
    "  axs[5,2].imshow(1-np.reshape(clean_letters[25],(7,5)), cmap='Greys',  interpolation='nearest')\n",
    "\n",
    "  axs[5,3].axis('off')\n",
    "  axs[5,4].axis('off')\n",
    "\n",
    "  plt.show()\n",
    "\n",
    "###############################################\n",
    "# Displays a single letter\n",
    "###############################################\n",
    "def show_letter(letter):\n",
    "  plt.imshow(1-np.reshape(letter,(7,5)), cmap='Greys',  interpolation='nearest')\n",
    "\n",
    "###############################################\n",
    "# Magnitude counter\n",
    "###############################################\n",
    "def get_mag(A):\n",
    "  return np.sum(A)\n",
    "\n",
    "###############################################\n",
    "# Importing data\n",
    "###############################################\n",
    "# This data set contains all the letter from A to Z\n",
    "# Each row is a vectorized version of the letter\n",
    "# Each letter image has 7x5 pixel dimensions\n",
    "# The data set is arranged such that A is the first row and Z is the last\n",
    "# We made them into arrays too for simplicity\n",
    "\n",
    "# clean_letters = convert_to_list(list(requests.get('https://raw.githubusercontent.com/rgantonio/CoE161---FileDump/main/letters.txt').text))\n",
    "with open(\"char_data.txt\") as data_file:\n",
    "  clean_letters = convert_to_list(data_file.read())\n",
    "clean_letters = np.array(clean_letters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Density: 0.048828125\n"
     ]
    }
   ],
   "source": [
    "###############################################\n",
    "# Set parameters\n",
    "###############################################\n",
    "D = 1024\n",
    "M = 50    # Number of ones\n",
    "N = 3     # Sliding window size\n",
    "m = 5     # Signature size\n",
    "K = 1     # CDT K factor\n",
    "print(\"Density: \" + str(M/D))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def u_gen_rand_hv(D):\n",
    "\n",
    "    # Sanity checker\n",
    "    if (D % 2):\n",
    "        print(\"Error - D can't be an odd number\")\n",
    "        return 0\n",
    "\n",
    "    hv = np.zeros(D, dtype = int)\n",
    "    indices = np.random.permutation(D)\n",
    "\n",
    "    hv[indices >= M] = 0\n",
    "    hv[indices < M] = 1\n",
    "\n",
    "    return hv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlap(A,B,D):\n",
    "    and_out = np.logical_and(A,B)\n",
    "    return np.sum(and_out)/D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perm(A,N):\n",
    "    return np.roll(A,N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def superimpose(block):\n",
    "    # Apply OR to all HV's in block\n",
    "    return np.array([1 if x >= 1 else 0 for x in sum(block)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def countones(Z):\n",
    "    count = 0\n",
    "    for i in Z:\n",
    "        count += i\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CDT(Z,K=1):\n",
    "    thinned_list = []\n",
    "    for k in range(1,K+1):\n",
    "        thinned_list.append(np.logical_and(Z, perm(Z,k)))\n",
    "    res = superimpose(thinned_list)\n",
    "    # print(countones(res)/D)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import and export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_im_char(D):\n",
    "  letter_im = dict()\n",
    "  f = open(\"char_im_man.txt\",\"r\")\n",
    "  for n in range(35):\n",
    "    line = f.readline()\n",
    "    line = list(line[-(D+2):-2])\n",
    "    line = [int(x) for x in line]\n",
    "    letter_im[n] = np.array(line)\n",
    "  \n",
    "  f.close()\n",
    "  return letter_im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_am_char(D, keys):\n",
    "  letter_am = dict()\n",
    "  f = open(\"char_am.txt\",\"r\")\n",
    "  for n in range(len(keys)):\n",
    "    line = f.readline()\n",
    "    line = list(line[0:1024])\n",
    "    line = [int(x) for x in line]\n",
    "    letter_am[keys[n]] = np.array(line)\n",
    "  \n",
    "  f.close()\n",
    "  return letter_am"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_am_lang(D, lang_labels):\n",
    "  lang_am = dict()\n",
    "  f = open(\"lang_am.txt\",\"r\")\n",
    "  for n in range(len(lang_labels)):\n",
    "    line = f.readline()\n",
    "    line = list(line[0:1024])\n",
    "    line = [int(x) for x in line]\n",
    "    lang_am[lang_labels[n]] = np.array(line)\n",
    "  \n",
    "  f.close()\n",
    "  return lang_am"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataclass containing the encoder programming\n",
    "@dataclass\n",
    "class Encodersettings:\n",
    "    sliding_window_mode: bool = 0\n",
    "    signature_encoding_mode: bool = 0\n",
    "    xor_binding_mode: bool = 0\n",
    "    shift_binding_mode: bool = 0\n",
    "    shift_amount: int = 0\n",
    "\n",
    "    or_mode: bool = 0\n",
    "    acc1_mode: bool = 0\n",
    "    cdt_mode: bool = 0\n",
    "    acc2_mode: bool = 0\n",
    "    cdt_k_fact: int = 1\n",
    "    thr1_val: int = 0\n",
    "    thr2_val: int = 0\n",
    "    window1_size: int = 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binarize_hv_thr(v, threshold):\n",
    "    \n",
    "    for i in range(len(v)):\n",
    "        if v[i] >= threshold:\n",
    "            v[i] = 1\n",
    "        else:\n",
    "            v[i] = 0\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buffer_to_binary(buffer):\n",
    "  letters = ['a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y','z',' ','\\n']\n",
    "  lang_data = \"\"\n",
    "  for i in range(len(buffer)):\n",
    "    if (buffer[i] not in letters):\n",
    "      print(\"Error: unknown letter encountered\")\n",
    "      return None\n",
    "    idx = letters.index(buffer[i])\n",
    "    bin_idx = bin(idx)[2:].zfill(6) # removes \"0b\" and adds zeros in front\n",
    "    lang_data = lang_data + bin_idx\n",
    "    if (i != len(buffer)-1):\n",
    "      lang_data += \"\\n\"\n",
    "  return lang_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(input_buffer, shift_amount_buffer, item_mem, D, enc_set):\n",
    "    window1_cnt = enc_set.window1_size\n",
    "    acc1_regs = np.zeros(D, dtype = int)\n",
    "    acc2_regs = np.zeros(D, dtype = int)\n",
    "    reg1_out = np.zeros(D, dtype = int)\n",
    "    win_counter = 0\n",
    "    in_value_queue = np.zeros(enc_set.window1_size, dtype = int)\n",
    "    i = -1\n",
    "    input_done = 0\n",
    "    \n",
    "    while not input_done:\n",
    "        \n",
    "        # BINDING\n",
    "        # lang_recog signature encoding\n",
    "        if (enc_set.sliding_window_mode):\n",
    "            enc_set.shift_binding_mode = 1\n",
    "            if (win_counter < (enc_set.window1_size-1) ) and i != -1:\n",
    "                win_counter += 1\n",
    "            else:\n",
    "                win_counter = 0\n",
    "                i += 1\n",
    "                input_value = input_buffer[i]\n",
    "                in_value_queue = np.insert(in_value_queue, 0, input_value)\n",
    "                in_value_queue = np.delete(in_value_queue,-1)\n",
    "            \n",
    "            in_value_mapper = in_value_queue[win_counter]\n",
    "            xor_tot = 0\n",
    "            if (enc_set.signature_encoding_mode):\n",
    "                for j in range(0,enc_set.window1_size):\n",
    "                    if (j != win_counter):\n",
    "                        xor_tot = np.bitwise_xor(xor_tot, in_value_queue[j])\n",
    "            shift_amount = win_counter + xor_tot\n",
    "            input_done = (i == len(input_buffer)-1) and (win_counter == enc_set.window1_size-1)\n",
    "            \n",
    "            im_en = (win_counter <= i)\n",
    "            \n",
    "        else:\n",
    "            i += 1\n",
    "            input_done = (i == len(input_buffer)-1)\n",
    "            input_value = input_buffer[i]\n",
    "\n",
    "            in_value_mapper = input_value\n",
    "            shift_amount = shift_amount_buffer[i]\n",
    "            im_en = 1\n",
    "\n",
    "        # Fetch HV from IM and CIM\n",
    "\n",
    "        if (im_en):\n",
    "            im_out = item_mem[in_value_mapper]\n",
    "        else:\n",
    "            im_out = np.zeros(D, dtype=int)\n",
    "        # cim_out = continuous_item_mem[in_value_mapper]\n",
    "        if (enc_set.xor_binding_mode):\n",
    "            # xor_out = np.logical_xor(im_out, cim_out)\n",
    "            xor_out = None\n",
    "        else:\n",
    "            xor_out = im_out\n",
    "\n",
    "        # Permutation\n",
    "        if (not enc_set.shift_binding_mode):\n",
    "            binding_out = xor_out\n",
    "        else:\n",
    "            binding_out = perm(xor_out, shift_amount)\n",
    "\n",
    "        # BUNDLING\n",
    "        thr1_out = np.zeros(D, dtype = int)\n",
    "        if (enc_set.or_mode):\n",
    "            if (input_done):\n",
    "                acc1_regs = np.logical_or(acc1_regs, binding_out)\n",
    "                window1_cnt -= 1\n",
    "                reg1_out = copy.deepcopy(acc1_regs)\n",
    "                stage1_done = 1\n",
    "            elif (window1_cnt > 0):\n",
    "                acc1_regs = np.logical_or(acc1_regs, binding_out)\n",
    "                window1_cnt -= 1\n",
    "                stage1_done = 0\n",
    "            else:\n",
    "                reg1_out = copy.deepcopy(acc1_regs)\n",
    "                window1_cnt = enc_set.window1_size - 1\n",
    "                acc1_regs = binding_out\n",
    "                stage1_done = 1\n",
    "\n",
    "        elif (enc_set.acc1_mode):\n",
    "            if (input_done):\n",
    "                acc1_regs += binding_out\n",
    "                window1_cnt -= 1\n",
    "                thr1_out = binarize_hv_thr(copy.deepcopy(acc1_regs), enc_set.thr1_val)\n",
    "                stage1_done = 1\n",
    "            elif (window1_cnt > 0):\n",
    "                acc1_regs += binding_out\n",
    "                window1_cnt -= 1\n",
    "                stage1_done = 0\n",
    "            else:\n",
    "                thr1_out = binarize_hv_thr(copy.deepcopy(acc1_regs), enc_set.thr1_val)\n",
    "                window1_cnt = enc_set.window1_size - 1\n",
    "                acc1_regs = binding_out\n",
    "                stage1_done = 1\n",
    "            reg1_out = thr1_out\n",
    "        else:\n",
    "            reg1_out = binding_out\n",
    "            stage1_done = 1\n",
    "\n",
    "        #Stage 2 bundling\n",
    "        thr2_out = np.zeros(D, dtype = int)\n",
    "        if (stage1_done):\n",
    "            if (enc_set.cdt_mode):\n",
    "                cdt_out = CDT(reg1_out,enc_set.cdt_k_fact)\n",
    "            else:\n",
    "                cdt_out = reg1_out\n",
    "\n",
    "            if (enc_set.acc2_mode):\n",
    "                acc2_regs += cdt_out\n",
    "                if (input_done):\n",
    "                    thr2_calc = enc_set.thr2_val * (i+1) * (2**(-10))\n",
    "                    thr2_out = binarize_hv_thr(copy.deepcopy(acc2_regs), thr2_calc)\n",
    "                reg2_out = thr2_out\n",
    "            else:\n",
    "                reg2_out = cdt_out\n",
    "    \n",
    "    return reg2_out\n",
    "            \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Character recognition\n",
    "encoded_lst = []\n",
    "for i in range(len(clean_letters)):\n",
    "    input_buffer = list(range(35))\n",
    "    letter = clean_letters[i]\n",
    "    shift_amount_buffer = []\n",
    "    for i in letter:\n",
    "        shift_amount_buffer.append(int(i))\n",
    "    # print(shift_amount_buffer)\n",
    "\n",
    "    item_mem = import_im_char(D)\n",
    "    enc_set_char = Encodersettings(\n",
    "        shift_binding_mode=1,\n",
    "        or_mode=1,\n",
    "        cdt_mode=1,\n",
    "        cdt_k_fact=1,\n",
    "        window1_size=35)\n",
    "\n",
    "    encoded_hv = encoder(input_buffer, shift_amount_buffer, item_mem, D, enc_set_char)\n",
    "    encoded_hv = [x for x in encoded_hv]\n",
    "    # print(encoded_hv)\n",
    "    encoded_lst.append(encoded_hv)\n",
    "\n",
    "# Check results with encoded HVs from char_testvector_gen\n",
    "f = open(\"char_after_cdt.txt\",\"r\")\n",
    "for j in range(len(clean_letters)):\n",
    "    line = f.readline()\n",
    "    line = list(line[0:1024])\n",
    "    line = [int(x) for x in line]\n",
    "\n",
    "    for i in range(len(encoded_hv)):\n",
    "        if (encoded_lst[j][i] != line[i]):\n",
    "            print(\"Error: letter \" + str(j) + \"pos: \" + str(i))\n",
    "\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Language recognition\n",
    "letters = ['a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y','z',' ','\\n']\n",
    "text = \"hello this is a test\"\n",
    "shift_amount_buffer = np.zeros(len(text),dtype=int)\n",
    "input_buffer = [letters.index(x) for x in text]\n",
    "# print(input_buffer)\n",
    "\n",
    "item_mem = import_im_char(D)\n",
    "enc_set_lang = Encodersettings(\n",
    "    sliding_window_mode=1,\n",
    "    signature_encoding_mode=1,\n",
    "    acc1_mode=1,\n",
    "    acc2_mode=1,\n",
    "    window1_size=3,\n",
    "    thr1_val = 2,\n",
    "    thr2_val = 20)\n",
    "\n",
    "encoded_hv = encoder(input_buffer, shift_amount_buffer, item_mem, D, enc_set_lang)\n",
    "encoded_hv = [x for x in encoded_hv]\n",
    "# print(encoded_hv)\n",
    "\n",
    "# Check results with encoded HVs from lang_testvector_gen\n",
    "f = open(\"lang_data_encoded.txt\",\"r\")\n",
    "line = f.readline()\n",
    "line = list(line[0:1024])\n",
    "line = [int(x) for x in line]\n",
    "\n",
    "for i in range(len(encoded_hv)):\n",
    "    if (encoded_hv[i] != line[i]):\n",
    "        print(\"Error: letter pos: \" + str(i))\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Density: 0.01171875\n",
      "Density: 0.4208984375\n",
      "Density: 0.205078125\n",
      "Density: 0.541015625\n",
      "Density: 0.1689453125\n",
      "Density: 0.0322265625\n",
      "Density: 0.2451171875\n"
     ]
    }
   ],
   "source": [
    "# Mixed testbench\n",
    "letters = ['a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y','z',' ','\\n']\n",
    "text = \"executing mixed test\"\n",
    "mixed_data = buffer_to_binary(text)\n",
    "if mixed_data is None:\n",
    "    print(\"Error\")\n",
    "f = open(\"mixed_data.txt\", \"w\")\n",
    "f.write(mixed_data)\n",
    "f.close()\n",
    "shift_amount_buffer = np.zeros(len(text),dtype=int)\n",
    "input_buffer = [letters.index(x) for x in text]\n",
    "# print(input_buffer)\n",
    "\n",
    "f = open(\"mixed_data_encoded.txt\", \"w\").close()\n",
    "item_mem = import_im_char(D)\n",
    "def mixed_test(item_mem, enc_set):\n",
    "  encoded_hv = encoder(input_buffer, shift_amount_buffer, item_mem, D, enc_set)\n",
    "  encoded_hv = [x for x in encoded_hv]\n",
    "  # print(encoded_hv)\n",
    "  print(\"Density: \" + str(countones(encoded_hv)/D))\n",
    "  hv = \"\".join(str(x) for x in encoded_hv)\n",
    "  f = open(\"mixed_data_encoded.txt\", \"a\")\n",
    "  f.write(str(hv) + \"\\n\")\n",
    "  f.close()\n",
    "  return\n",
    "\n",
    "# Mixed tests\n",
    "# Lang with other input and thr\n",
    "enc_set_mixed = Encodersettings(\n",
    "  sliding_window_mode=1,\n",
    "  signature_encoding_mode=1,\n",
    "  acc1_mode=1,\n",
    "  acc2_mode=1,\n",
    "  window1_size=3,\n",
    "  or_mode=0,\n",
    "  cdt_mode=0,\n",
    "  cdt_k_fact=1,\n",
    "  thr1_val=2,\n",
    "  thr2_val=100)\n",
    "mixed_test(item_mem, enc_set_mixed)\n",
    "\n",
    "# Max sliding window size\n",
    "enc_set_mixed = Encodersettings(\n",
    "  sliding_window_mode=1,\n",
    "  signature_encoding_mode=1,\n",
    "  acc1_mode=1,\n",
    "  acc2_mode=1,\n",
    "  window1_size=12,\n",
    "  or_mode=0,\n",
    "  cdt_mode=0,\n",
    "  cdt_k_fact=1,\n",
    "  thr1_val=2,\n",
    "  thr2_val=100)\n",
    "mixed_test(item_mem, enc_set_mixed)\n",
    "\n",
    "# Sliding window without signature encoding\n",
    "enc_set_mixed = Encodersettings(\n",
    "  sliding_window_mode=1,\n",
    "  signature_encoding_mode=0,\n",
    "  acc1_mode=1,\n",
    "  acc2_mode=1,\n",
    "  window1_size=4,\n",
    "  or_mode=0,\n",
    "  cdt_mode=0,\n",
    "  cdt_k_fact=1,\n",
    "  thr1_val=2,\n",
    "  thr2_val=20)\n",
    "mixed_test(item_mem, enc_set_mixed)\n",
    "\n",
    "# Other window and or_mode instead of acc1\n",
    "enc_set_mixed = Encodersettings(\n",
    "  sliding_window_mode=1,\n",
    "  signature_encoding_mode=1,\n",
    "  acc1_mode=0,\n",
    "  acc2_mode=1,\n",
    "  window1_size=2,\n",
    "  or_mode=1,\n",
    "  cdt_mode=0,\n",
    "  cdt_k_fact=1,\n",
    "  thr1_val=2,\n",
    "  thr2_val=100)\n",
    "mixed_test(item_mem, enc_set_mixed)\n",
    "\n",
    "# or_mode and cdt_mode followed by acc2\n",
    "enc_set_mixed = Encodersettings(\n",
    "  sliding_window_mode=1,\n",
    "  signature_encoding_mode=1,\n",
    "  acc1_mode=0,\n",
    "  acc2_mode=1,\n",
    "  window1_size=2,\n",
    "  or_mode=1,\n",
    "  cdt_mode=1,\n",
    "  cdt_k_fact=1,\n",
    "  thr1_val=2,\n",
    "  thr2_val=50)\n",
    "mixed_test(item_mem, enc_set_mixed)\n",
    "\n",
    "# Only cdt, no bundling in stage1\n",
    "enc_set_mixed = Encodersettings(\n",
    "  sliding_window_mode=0,\n",
    "  signature_encoding_mode=0,\n",
    "  acc1_mode=0,\n",
    "  acc2_mode=1,\n",
    "  window1_size=1,\n",
    "  or_mode=0,\n",
    "  cdt_mode=1,\n",
    "  cdt_k_fact=1,\n",
    "  thr1_val=2,\n",
    "  thr2_val=50)\n",
    "mixed_test(item_mem, enc_set_mixed)\n",
    "\n",
    "# Only stage 2 bundling, no bundling in stage1\n",
    "enc_set_mixed = Encodersettings(\n",
    "  sliding_window_mode=0,\n",
    "  signature_encoding_mode=0,\n",
    "  acc1_mode=0,\n",
    "  acc2_mode=1,\n",
    "  window1_size=1,\n",
    "  or_mode=0,\n",
    "  cdt_mode=0,\n",
    "  cdt_k_fact=1,\n",
    "  thr1_val=2,\n",
    "  thr2_val=100)\n",
    "mixed_test(item_mem, enc_set_mixed)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "a7f2bb35f441a7b46a8c8fdc57bf30046ff09601f5a689a15e8268768a19b65a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
